# v0.3 Batch 2: Validation Engine

**Goal**: Build the infrastructure that catches regressions as they happen. Test baseline, flake detection, cross-task validation, failure taxonomy.

**Duration estimate**: 2–3 days  
**Depends on**: Batch 1 (config keys, AT-7 fix for clean baseline) ✅ Complete  
**Status**: Not started

---

## Deliverables

### 2.1 Test baseline capture

Before execute phase begins, capture which tests pass and which fail. This becomes the "known state" — we only block on *new* failures.

**New module**: `src/workflow/test-baseline.ts`

**Interface**:
```typescript
export interface TestResult {
  name: string;          // test name or file path
  passed: boolean;
  duration?: number;     // ms
  output?: string;       // truncated stderr/stdout on failure
}

export interface TestBaseline {
  capturedAt: number;    // timestamp
  sha: string;           // git SHA at capture
  command: string;       // the test command used
  results: TestResult[];
  knownFailures: string[]; // test names that failed at baseline
}

/** Run test command, parse output, return baseline. */
export async function captureBaseline(
  testCommand: string,
  cwd: string,
): Promise<TestBaseline>;

/** Compare current test run against baseline. Classify each failure. */
export function classifyFailures(
  current: TestResult[],
  baseline: TestBaseline,
): ClassifiedResults;

export interface ClassifiedResults {
  newFailures: TestResult[];      // tests that passed in baseline, fail now → BLOCK
  preExisting: TestResult[];      // tests that failed in baseline too → IGNORE
  flakeCandidates: TestResult[];  // tests to re-run for flake detection
  newPasses: TestResult[];        // tests that failed in baseline, pass now → good news
}
```

**Persistence**: Baseline stored in `OrchestratorState` as `testBaseline?: TestBaseline`. Captured once at execute-phase start, before any tasks run.

**Test output parsing**: Start simple — run command, collect exit code + stderr. Parse individual test names from common frameworks (vitest/jest output: `✓ test name` / `✗ test name`). If parsing fails, fall back to binary pass/fail for the whole suite.

**Test**: Unit tests for `classifyFailures` with mock baselines. Integration test: `captureBaseline` with a real `bun test` on a fixture project.

### 2.2 Cross-task test suite

After a task passes its own reviews, run the full test suite and classify failures against baseline.

**Changes to `execute.ts`**:
- New step between review completion and task-complete: `runCrossTaskValidation()`.
- Respects `validationCadence` from config:
  - `"every"` — run after every task (default)
  - `"every-N"` — run every N tasks (use `validationInterval`)
  - `"on-demand"` — skip unless triggered by checkpoint

**Interface**:
```typescript
// New in execute.ts or extracted to validation.ts
export async function runCrossTaskValidation(
  testCommand: string,
  baseline: TestBaseline,
  cwd: string,
): Promise<ValidationResult>;

export interface ValidationResult {
  passed: boolean;
  classified: ClassifiedResults;
  flakyTests: string[];           // tests that flipped on re-run
  blockingFailures: TestResult[]; // genuine new regressions
}
```

**Flake detection**: For each `flakeCandidate` (new failure), re-run the test suite once. If the test passes on re-run, classify as flaky (warn, continue). If it still fails, it's a genuine regression (block).

**On blocking failure**: Invoke the existing `escalate()` function with the failure details. The user sees: "Task N introduced test regression: [test names]. Retry / Rollback / Skip / Abort."

**Test**: Unit test with mock test runner: simulate baseline + new failure → blocks. Simulate flake (pass on re-run) → warns, continues. Simulate pre-existing failure → ignored.

### 2.3 Pre-review validation gate

Run `validationCommand` (default: `tsc --noEmit`) after implementation, before dispatching reviewers. Catches syntax/type errors cheaply.

**Changes**: This already exists in `execute.ts` as the "VALIDATION GATE" section. Refine it:
- Use `config.validationCommand` (already wired).
- On failure, instead of escalating immediately, give the implementer one auto-fix attempt: dispatch with the error output and "fix these type errors."
- After auto-fix, re-run validation. If still fails, then escalate.

**Interface**: No new types. Enhances existing `runValidation()`.

**Test**: Already has test coverage. Add test for the auto-fix-then-revalidate path.

### 2.4 Failure taxonomy

Codify the failure classification table from the roadmap into a type system that the execute phase uses for default actions.

**New types in `orchestrator-state.ts`** (or a new `failure-taxonomy.ts`):

```typescript
export type FailureType =
  | "parse-error"
  | "test-regression"
  | "test-flake"
  | "test-preexisting"
  | "tool-timeout"
  | "budget-threshold"
  | "review-max-retries"
  | "validation-failure"
  | "impl-crash";

export type FailureAction =
  | "auto-retry"
  | "warn-continue"
  | "ignore"
  | "stop-show-diff"
  | "retry-then-escalate"
  | "checkpoint"
  | "escalate";

export const DEFAULT_FAILURE_ACTIONS: Record<FailureType, FailureAction> = {
  "parse-error": "auto-retry",
  "test-regression": "stop-show-diff",
  "test-flake": "warn-continue",
  "test-preexisting": "ignore",
  "tool-timeout": "retry-then-escalate",
  "budget-threshold": "checkpoint",
  "review-max-retries": "escalate",
  "validation-failure": "retry-then-escalate",
  "impl-crash": "retry-then-escalate",
};

/** Given a failure, return what to do. */
export function resolveFailureAction(
  type: FailureType,
  overrides?: Partial<Record<FailureType, FailureAction>>,
): FailureAction;
```

**Integration**: Replace the ad-hoc `if/else` escalation paths in `execute.ts` with calls to `resolveFailureAction()`. The escalation function maps actions to behavior:
- `auto-retry` → retry without user intervention
- `warn-continue` → `ui.notify` warning, proceed
- `stop-show-diff` → show diff vs baseline, then escalate
- `checkpoint` → trigger checkpoint (Batch 4 delivers this)
- `escalate` → existing `escalate()` function

**Test**: Unit test for `resolveFailureAction`. Integration test: mock a `test-flake` failure → verify it warns and continues (doesn't block).

---

## Exit criteria

- Cross-task validation catches a genuine regression in our own test suite (demonstrated by temporarily breaking a test).
- Flake policy correctly distinguishes flaky vs genuine (test with a mock that flips).
- Pre-existing test failures don't block execution.
- Failure taxonomy drives all escalation paths in execute phase.

---

## Cross-cutting concerns

### State schema migration

New fields added to `OrchestratorState` and `TaskExecState` must be optional (`?`) for backward compatibility with in-flight workflows. When loading state, missing fields get defaults:

```typescript
state.testBaseline ??= undefined;
```

### Testing strategy

- **Unit tests** for all pure functions (classifyFailures, resolveFailureAction, test output parsers).
- **Integration tests** for state transitions (mock dispatch, real state machine).
- **At least one acceptance test** that exercises the end-to-end validation flow.

### New files

| File | Purpose |
|------|---------|
| `src/workflow/test-baseline.ts` | Test baseline capture & failure classification |
| `src/workflow/failure-taxonomy.ts` | Failure types, default actions, resolution |

### Modified files

| File | Changes |
|------|---------|
| `src/workflow/orchestrator-state.ts` | New `testBaseline` state field |
| `src/workflow/phases/execute.ts` | Cross-task validation step, auto-fix path, failure taxonomy integration |
