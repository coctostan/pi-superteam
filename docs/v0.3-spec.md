# v0.3 Design Spec — Continuous Validation & Course Correction

**Status**: Draft for review  
**Author**: Architect  
**Date**: 2026-02-08  
**Derived from**: [ROADMAP.md](ROADMAP.md) v0.3 section, [post-run-1-assessment.md](post-run-1-assessment.md)

---

## Executive Summary

v0.3 makes the execute phase self-correcting. Run 1 proved this is the most dangerous gap — task 19 broke AT-7 silently, cost was invisible, and there was no way to steer mid-execution.

The milestone is large. This spec proposes **4 dev batches** with clear boundaries, each independently testable and deployable. Batches build on each other but each delivers standalone value.

```
Batch 1: Foundations        → prereq fixes, streaming, plan-review discipline, config
Batch 2: Validation Engine  → test baseline, cross-task validation, flake policy, failure taxonomy
Batch 3: Git Discipline     → safety preflight, orchestrator commits, enhanced rollback
Batch 4: Checkpoints & UX   → progress summaries, pause points, minimal plan revision, context forwarding
```

### Dependency graph

```
Batch 1 (Foundations)
  ├──→ Batch 2 (Validation Engine)
  │       └──→ Batch 4 (Checkpoints & UX)
  └──→ Batch 3 (Git Discipline)
            └──→ Batch 4 (Checkpoints & UX)
```

Batches 2 and 3 are independent of each other and could be developed in parallel. Batch 4 depends on both.

---

## Open Questions for CTO

Before finalizing, I need decisions on these ambiguities in the roadmap:

### Q1: Two state systems — consolidate?

There are two parallel state systems:
- `state.ts` — `WorkflowState` with its own persistence via `piRef.appendEntry()`. Still used for plan parsing (`parseTaskBlock`, `parseTaskHeadings`) and the status widget.
- `orchestrator-state.ts` — `OrchestratorState` with file-based persistence (`.superteam-workflow.json`). This is what the orchestrator actually drives.

They have overlapping types (`PlanTask` vs `TaskExecState`, `TaskStatus` overlap). The plan parsing functions in `state.ts` are imported by `plan-review.ts` to re-parse after revision.

**Options**:
- (A) Consolidate into `orchestrator-state.ts` — move plan parsing there, deprecate `state.ts` entirely. Clean but larger diff.
- (B) Extract plan parsing into its own module (`plan-parser.ts`), let `state.ts` atrophy. Minimal disruption.
- (C) Leave as-is — `state.ts` is the `team` tool's state, `orchestrator-state.ts` is the workflow's. They serve different code paths.

**My recommendation**: (B). The plan parser is pure logic that both code paths need. The widget code in `state.ts` is already unused by the orchestrator. Extract the parser, don't fight the rest.

### Q2: Orchestrator commits vs implementer commits

Currently the implementer prompt says: *"Commit after each green cycle."* The roadmap says orchestrator should commit with standardized messages.

**Tension**: If implementers commit (which they already do), orchestrator commits on top create a messy history. If we tell implementers NOT to commit, we lose the intra-task safety net of per-green-cycle commits.

**Options**:
- (A) Implementers stop committing. Orchestrator commits after task passes all reviews. Single clean commit per task. Rollback is clean (one SHA per task). Risk: if implementer crashes mid-task, no intermediate saves.
- (B) Implementers keep committing. Orchestrator squashes all intra-task commits into one after reviews pass. History is clean, intra-task safety retained. More complex git logic.
- (C) Implementers keep committing freely. Orchestrator records the pre-task SHA for rollback but doesn't commit itself. Per-task commits are a future squash in v0.5. Simplest.

**My lean**: (A) for simplicity. The implementer's work is ephemeral until reviews pass. If it crashes, we rollback to pre-task SHA and retry anyway. But this is a significant behavioral change — want your take.

### Q3: `validationCommand` vs cross-task test suite

The roadmap describes two validations:
1. **Pre-review validation gate**: `tsc --noEmit` or equivalent — lightweight, catches syntax errors before wasting a review cycle.
2. **Cross-task test suite**: Full test suite — catches regressions across tasks.

Currently `config.validationCommand` defaults to `"tsc --noEmit"` and runs once (post-impl, pre-review).

**Question**: Should these be two separate config keys? E.g.:
- `validationCommand`: lightweight pre-review check (type-check). Runs every task.
- `testCommand`: full test suite. Runs per `validationCadence`.

Or is `validationCommand` overloaded to serve both roles?

**My recommendation**: Two keys. They serve different purposes and have different cost profiles. `validationCommand` is cheap and should always run. `testCommand` is expensive and cadence-controlled.

### Q4: Budget checkpoint threshold

Roadmap says *"In auto mode, checkpoints fire only on test failure or budget threshold."*

What's the threshold? Options:
- (A) Percentage of `costs.hardLimitUsd` (e.g., 80%)
- (B) Percentage of estimated remaining cost (e.g., actual > 1.5× estimate)
- (C) Absolute intervals (e.g., every $10 spent)
- (D) Use `costs.warnAtUsd` as the checkpoint trigger — it already exists in config

**My lean**: (D). `warnAtUsd` already exists (default $5). First hit triggers a checkpoint. After user continues, next checkpoint at `hardLimitUsd`. Simple, no new config.

### Q5: What happens when plan revision drops a currently-executing task?

The minimal revision allows "drop remaining tasks, reorder, skip." But what if the user wants to split a large task into two smaller ones? The roadmap says "no new task insertion." Is splitting out of scope?

**My lean**: Yes, out of scope for v0.3. Splitting = insert. The user can effectively achieve it by: keeping the task, adding a note in description ("only do X part"), and accepting that "Y part" is deferred. Clean splitting is v0.4 territory (chunking for breadth).

### Q6: Flake detection — how many retries?

Roadmap says *"re-run once; if the result flips, classify as flake."* Is "once" always right? Some test suites have timing-sensitive tests that need 2-3 runs to stabilize.

**My lean**: One re-run is the right default. Configurable later if needed. More retries = more cost for a false sense of confidence.

---

## Batch 1: Foundations

**Goal**: Fix the prerequisite issues that make continuous validation meaningless. Without streaming, users can't see what's happening. Without the AT-7 fix, the baseline is broken. Without plan-review discipline, the system wastes review cycles on wrong-level feedback.

**Duration estimate**: 1–2 days

### Deliverables

#### 1.1 Fix AT-7 regression
The brainstorm acceptance test was broken by the skip feature (task 19 in run 1). The `ui.select` mock for the skip prompt is missing, so the test never exercises the full brainstorm flow.

**Change**: Add the missing mock in `brainstorm.acceptance.test.ts` that handles the "Start brainstorm" / "Skip brainstorm" select prompt.

**Test**: AT-7 passes again. All existing acceptance tests pass.

#### 1.2 Streaming feedback for all phases
Brainstorm, plan-write, and plan-review dispatch agents with no `onStreamEvent` callback. The UI freezes for 10–60+ seconds.

**Changes**:
- `phases/brainstorm.ts` — already has `makeOnStreamEvent()` wired in. ✅ Verify it's actually flowing to all dispatch calls including the retry path.
- `phases/plan-write.ts` — wire `makeOnStreamEvent()` into the planner dispatch.
- `phases/plan-review.ts` — wire `makeOnStreamEvent()` into reviewer and planner revision dispatches. Currently `dispatchReviewers()` passes a single `onStreamEvent` to `Promise.all` — verify this works correctly with parallel dispatches.

**Interface**: No new interfaces. Uses existing `OnStreamEvent` type and `createActivityBuffer` from `ui.ts`.

**Test**: Unit test that verifies `onStreamEvent` is passed to every `dispatchAgent` call in each phase. Mock-based — assert the callback argument is non-undefined.

#### 1.3 Plan review role separation
The reviewer should judge (pass/fail + findings), not fix. The planner applies fixes.

**Changes**:
- Update `agents/spec-reviewer.md` and `agents/architect.md` system prompts: explicitly state scope is structure/completeness/dependencies/granularity. NOT inline test code, argument indices, or line-level correctness. Add: "You MUST NOT modify any files. Your output is a review verdict only."
- Update `agents/planner.md`: "Apply targeted patches based on review findings. Do NOT rewrite the entire plan. Only modify sections referenced in findings."

**Interface**: No code interface changes. Prompt-level discipline.

**Test**: Manual verification via a workflow run. Measurable: plan-review cycles should converge in ≤2 iterations (vs 4+ in run 1).

#### 1.4 Reviewer write-guard
Runtime enforcement that reviewers don't write files.

**Changes**:
- New function in `dispatch.ts`: `hasWriteToolCalls(messages: Message[]): boolean` — scans agent messages for tool calls to `write`, `edit`, or `bash` commands containing write operations (heuristic: `>`, `>>`, `tee`, `sed -i`, `mv`, `cp`).
- In `plan-review.ts` and `execute.ts` review loops: after dispatch, check `hasWriteToolCalls(result.messages)`. If true, log warning via `ui.notify`, discard result, re-dispatch (once). If still writes on retry, escalate to user.

**Interface**:
```typescript
// dispatch.ts
export function hasWriteToolCalls(messages: Message[]): boolean;
```

**Test**: Unit test with mock messages containing write tool calls → returns true. Messages with only read tools → returns false. Integration test in review loop: mock reviewer that writes → gets re-dispatched.

#### 1.5 Plan revision strategy — targeted patches
Replace full-plan rewrites with targeted patches.

**Changes**:
- New prompt: `buildTargetedPlanRevisionPrompt(planContent, findings, designContent)` — instructs planner to "edit only the tasks mentioned in findings. Do not rewrite other tasks. Preserve task IDs."
- In `plan-review.ts`: replace `buildPlanRevisionPromptFromFindings` calls with the targeted variant.
- Add convergence check: after N cycles (default 2), if same findings recur, escalate to user with `ui.select`: "Approve as-is / Provide guidance / Abort".

**Interface**:
```typescript
// prompt-builder.ts
export function buildTargetedPlanRevisionPrompt(
  planContent: string,
  findings: string,
  designContent: string,
): string;
```

**Test**: Unit test for the prompt builder. Integration test: mock reviewer that fails with same finding twice → user escalation fires.

#### 1.6 Minimal config story
Define what v0.3 reads from `.superteam.json`. Currently the config is rich but v0.3 adds:

**New config keys** (added to `SuperteamConfig` in `config.ts`):
```typescript
// Added to SuperteamConfig
testCommand: string;              // e.g., "bun test" — override auto-detection
validationCadence: "every" | "every-N" | "on-demand";
validationInterval: number;       // N for "every-N" (default: 3)
budgetCheckpointUsd: number;      // dollar threshold for auto-mode checkpoint (default: uses costs.warnAtUsd)
gitIgnorePatterns: string[];      // files to exclude from orchestrator commits/diffs
```

**Changes**: Add to `SuperteamConfig` interface and `DEFAULT_CONFIG`. No schema validation — just merge-and-use.

**Test**: Unit test: config with new keys loads correctly. Config without them gets defaults.

### Batch 1 exit criteria
- All acceptance tests pass (including AT-7).
- Streaming visibly works in all phases (no >5s frozen UI).
- Plan review converges in ≤2 automated cycles on a test workflow.
- Reviewer write-guard catches a write attempt in test.

---

## Batch 2: Validation Engine

**Goal**: Build the infrastructure that catches regressions as they happen. Test baseline, flake detection, cross-task validation, failure taxonomy.

**Duration estimate**: 2–3 days  
**Depends on**: Batch 1 (config keys, AT-7 fix for clean baseline)

### Deliverables

#### 2.1 Test baseline capture

Before execute phase begins, capture which tests pass and which fail. This becomes the "known state" — we only block on *new* failures.

**New module**: `src/workflow/test-baseline.ts`

**Interface**:
```typescript
export interface TestResult {
  name: string;          // test name or file path
  passed: boolean;
  duration?: number;     // ms
  output?: string;       // truncated stderr/stdout on failure
}

export interface TestBaseline {
  capturedAt: number;    // timestamp
  sha: string;           // git SHA at capture
  command: string;       // the test command used
  results: TestResult[];
  knownFailures: string[]; // test names that failed at baseline
}

/** Run test command, parse output, return baseline. */
export async function captureBaseline(
  testCommand: string,
  cwd: string,
): Promise<TestBaseline>;

/** Compare current test run against baseline. Classify each failure. */
export function classifyFailures(
  current: TestResult[],
  baseline: TestBaseline,
): ClassifiedResults;

export interface ClassifiedResults {
  newFailures: TestResult[];      // tests that passed in baseline, fail now → BLOCK
  preExisting: TestResult[];      // tests that failed in baseline too → IGNORE
  flakeCandidates: TestResult[];  // tests to re-run for flake detection
  newPasses: TestResult[];        // tests that failed in baseline, pass now → good news
}
```

**Persistence**: Baseline stored in `OrchestratorState` as `testBaseline?: TestBaseline`. Captured once at execute-phase start, before any tasks run.

**Test output parsing**: Start simple — run command, collect exit code + stderr. Parse individual test names from common frameworks (vitest/jest output: `✓ test name` / `✗ test name`). If parsing fails, fall back to binary pass/fail for the whole suite.

**Test**: Unit tests for `classifyFailures` with mock baselines. Integration test: `captureBaseline` with a real `bun test` on a fixture project.

#### 2.2 Cross-task test suite

After a task passes its own reviews, run the full test suite and classify failures against baseline.

**Changes to `execute.ts`**:
- New step between review completion and task-complete: `runCrossTaskValidation()`.
- Respects `validationCadence` from config:
  - `"every"` — run after every task (default)
  - `"every-N"` — run every N tasks (use `validationInterval`)
  - `"on-demand"` — skip unless triggered by checkpoint

**Interface**:
```typescript
// New in execute.ts or extracted to validation.ts
export async function runCrossTaskValidation(
  testCommand: string,
  baseline: TestBaseline,
  cwd: string,
): Promise<ValidationResult>;

export interface ValidationResult {
  passed: boolean;
  classified: ClassifiedResults;
  flakyTests: string[];           // tests that flipped on re-run
  blockingFailures: TestResult[]; // genuine new regressions
}
```

**Flake detection**: For each `flakeCandidate` (new failure), re-run the test suite once. If the test passes on re-run, classify as flaky (warn, continue). If it still fails, it's a genuine regression (block).

**On blocking failure**: Invoke the existing `escalate()` function with the failure details. The user sees: "Task N introduced test regression: [test names]. Retry / Rollback / Skip / Abort."

**Test**: Unit test with mock test runner: simulate baseline + new failure → blocks. Simulate flake (pass on re-run) → warns, continues. Simulate pre-existing failure → ignored.

#### 2.3 Pre-review validation gate

Run `validationCommand` (default: `tsc --noEmit`) after implementation, before dispatching reviewers. Catches syntax/type errors cheaply.

**Changes**: This already exists in `execute.ts` as the "VALIDATION GATE" section. Refine it:
- Use `config.validationCommand` (already wired).
- On failure, instead of escalating immediately, give the implementer one auto-fix attempt: dispatch with the error output and "fix these type errors."
- After auto-fix, re-run validation. If still fails, then escalate.

**Interface**: No new types. Enhances existing `runValidation()`.

**Test**: Already has test coverage. Add test for the auto-fix-then-revalidate path.

#### 2.4 Failure taxonomy

Codify the failure classification table from the roadmap into a type system that the execute phase uses for default actions.

**New types in `orchestrator-state.ts`** (or a new `failure-taxonomy.ts`):

```typescript
export type FailureType =
  | "parse-error"
  | "test-regression"
  | "test-flake"
  | "test-preexisting"
  | "tool-timeout"
  | "budget-threshold"
  | "review-max-retries"
  | "validation-failure"
  | "impl-crash";

export type FailureAction =
  | "auto-retry"
  | "warn-continue"
  | "ignore"
  | "stop-show-diff"
  | "retry-then-escalate"
  | "checkpoint"
  | "escalate";

export const DEFAULT_FAILURE_ACTIONS: Record<FailureType, FailureAction> = {
  "parse-error": "auto-retry",
  "test-regression": "stop-show-diff",
  "test-flake": "warn-continue",
  "test-preexisting": "ignore",
  "tool-timeout": "retry-then-escalate",
  "budget-threshold": "checkpoint",
  "review-max-retries": "escalate",
  "validation-failure": "retry-then-escalate",
  "impl-crash": "retry-then-escalate",
};

/** Given a failure, return what to do. */
export function resolveFailureAction(
  type: FailureType,
  overrides?: Partial<Record<FailureType, FailureAction>>,
): FailureAction;
```

**Integration**: Replace the ad-hoc `if/else` escalation paths in `execute.ts` with calls to `resolveFailureAction()`. The escalation function maps actions to behavior:
- `auto-retry` → retry without user intervention
- `warn-continue` → `ui.notify` warning, proceed
- `stop-show-diff` → show diff vs baseline, then escalate
- `checkpoint` → trigger checkpoint (Batch 4 delivers this)
- `escalate` → existing `escalate()` function

**Test**: Unit test for `resolveFailureAction`. Integration test: mock a `test-flake` failure → verify it warns and continues (doesn't block).

### Batch 2 exit criteria
- Cross-task validation catches a genuine regression in our own test suite (demonstrated by temporarily breaking a test).
- Flake policy correctly distinguishes flaky vs genuine (test with a mock that flips).
- Pre-existing test failures don't block execution.
- Failure taxonomy drives all escalation paths in execute phase.

---

## Batch 3: Git Discipline

**Goal**: Make the git history reliable and orchestrator-controlled. Clean commits, dirty-tree safety, branch awareness.

**Duration estimate**: 1–2 days  
**Depends on**: Batch 1 (config keys for `gitIgnorePatterns`)  
**Independent of**: Batch 2

### Deliverables

#### 3.1 Git safety preflight

Before workflow starts (top of `runWorkflowLoop` or at brainstorm phase start), check git state.

**New module**: `src/workflow/git-preflight.ts`

**Interface**:
```typescript
export interface GitPreflightResult {
  clean: boolean;
  branch: string;
  isMainBranch: boolean;    // main, master, or configured protected branches
  uncommittedFiles: string[];
  warnings: string[];       // human-readable warnings
}

/** Check git state. Does NOT modify the repo. */
export async function runGitPreflight(cwd: string): Promise<GitPreflightResult>;
```

**Behavior**:
1. Check `git status --porcelain`. If dirty:
   - Present via `ui.select`: "Working tree has uncommitted changes. Stash / Commit first / Continue anyway / Abort"
   - "Stash" runs `git stash push -m "superteam-workflow-preflight"` automatically.
2. Check current branch. If `main` or `master`:
   - Warn via `ui.select`: "You're on main. Create branch / Continue on main / Abort"
   - "Create branch" prompts for name (default: `workflow/<slug>`), runs `git checkout -b <name>`.
3. Record `startingSha` in `OrchestratorState` for rollback baseline.

**State addition**:
```typescript
// Added to OrchestratorState
gitStartingSha?: string;
gitBranch?: string;
```

**Test**: Unit tests with mock git commands. Test dirty tree → stash path. Test main branch → branch creation path.

#### 3.2 Orchestrator-controlled commits

After a task passes all reviews (and cross-task validation when Batch 2 is present), the orchestrator commits.

**Changes to `git-utils.ts`**:
```typescript
/** Stage and commit all changes with a standardized message. */
export async function commitTaskChanges(
  cwd: string,
  taskId: number,
  taskTitle: string,
  ignorePatterns?: string[],
): Promise<{ sha: string; success: boolean }>;
```

**Behavior**:
1. `git add -A` (or selective add respecting `gitIgnorePatterns` from config).
2. `git commit -m "workflow: task ${taskId} — ${taskTitle}"`.
3. Return the new commit SHA.
4. Store SHA in `TaskExecState.commitSha`.

**State addition**:
```typescript
// Added to TaskExecState
commitSha?: string;
```

**Changes to `execute.ts`**:
- After task marked complete (step h), call `commitTaskChanges()`.
- Store the returned SHA in the task state.
- If commit fails (nothing to commit, git error), warn but don't block.

**Implementer prompt change** (depends on Q2 resolution):
- If Option A: Remove "Commit after each green cycle" from `buildImplPrompt`. Add: "Do NOT commit. The orchestrator manages commits."
- If Option B: Keep current prompt. Add squash after reviews pass.

**Test**: Integration test with a real git repo (temp dir): run mock task → verify commit message format → verify SHA stored. Test with `gitIgnorePatterns` → excluded files not staged.

#### 3.3 Enhanced rollback on escalation

The existing `escalate()` function offers Rollback. Enhance it with orchestrator commit awareness.

**Changes to `execute.ts` escalation**:
- Rollback now uses `task.gitShaBeforeImpl` (already tracked) to `resetToSha()`.
- After rollback, clean up: if orchestrator-controlled commits exist post-rollback SHA, they're gone (expected — `reset --hard` removes them).
- Show what's being rolled back: "Rolling back task N. Reverting N files changed since SHA abc1234."

**Test**: Integration test: implement task → commit → rollback → verify repo state matches pre-task SHA.

### Batch 3 exit criteria
- Workflow refuses to start on dirty working tree (offers stash).
- Warning on main branch with branch creation option.
- Orchestrator commits land with `workflow: task N — <title>` format.
- Rollback reverts to pre-task state cleanly.
- `gitIgnorePatterns` excludes configured files from staging.

---

## Batch 4: Checkpoints & UX

**Goal**: Give the user control during execution. Cost visibility, pause points, plan adjustment, context forwarding.

**Duration estimate**: 2–3 days  
**Depends on**: Batch 2 (validation triggers checkpoints), Batch 3 (commit SHAs in progress)

### Deliverables

#### 4.1 Progress summaries with cost

After each task completes, emit a deterministic summary. No LLM needed — computed from `OrchestratorState`.

**New function in `progress.ts`** (or `ui.ts`):
```typescript
export interface TaskProgressSummary {
  tasksCompleted: number;
  tasksRemaining: number;
  tasksSkipped: number;
  cumulativeCost: number;
  estimatedRemainingCost: number; // (cumulativeCost / tasksCompleted) * tasksRemaining
  changedFilesSoFar: string[];
  fixCyclesSoFar: number;
  currentTaskTitle: string;
}

export function computeProgressSummary(state: OrchestratorState): TaskProgressSummary;
export function formatProgressSummary(summary: TaskProgressSummary): string;
```

**Display**: `ui.notify(formatProgressSummary(summary), "info")` after each task completion.

**Widget update**: Update `workflow-progress` widget with live cost + completion percentage.

**Test**: Unit test for `computeProgressSummary` with various state snapshots. Test estimated cost calculation.

#### 4.2 Checkpoint pause points

At configurable intervals, pause execution and prompt the user.

**Checkpoint triggers** (any of):
1. Every task (when `executionMode === "checkpoint"` — already exists).
2. Test failure in cross-task validation → forced checkpoint.
3. Budget threshold hit (`cumulativeCost >= costs.warnAtUsd`) → checkpoint.
4. Budget hard limit approaching (`cumulativeCost >= costs.hardLimitUsd * 0.9`) → checkpoint.

**Checkpoint UI**:
```typescript
async function presentCheckpoint(
  state: OrchestratorState,
  trigger: "scheduled" | "test-failure" | "budget-warning" | "budget-critical",
  details?: string,
  ui: any,
): Promise<"continue" | "adjust" | "abort">;
```

Displays:
```
Checkpoint: 5/20 tasks done | $15.00 spent | ~$33.00 remaining
Trigger: [scheduled / test failure in X / budget warning]
[Continue] [Adjust plan] [Abort]
```

**Integration in `execute.ts`**:
- After task completion + validation + commit, check checkpoint triggers.
- If triggered, call `presentCheckpoint()`.
- On "continue" → proceed.
- On "adjust" → enter plan revision mode (4.3).
- On "abort" → set `state.error`, return.

**Test**: Unit test: mock state at 50% completion + budget at warnAtUsd → checkpoint fires. Mock state under budget → no checkpoint. Test failure trigger → forces checkpoint regardless of cadence.

#### 4.3 Minimal plan revision at checkpoints

When user selects "Adjust plan" at a checkpoint, present the remaining tasks for subtractive editing.

**Interface**:
```typescript
export interface PlanAdjustment {
  droppedTaskIds: number[];
  skippedTaskIds: number[];
  reorderedTaskIds?: number[];  // new ordering of remaining task IDs
}

/** Present remaining tasks for adjustment. Returns the changes. */
async function presentPlanRevision(
  state: OrchestratorState,
  ui: any,
): Promise<PlanAdjustment | null>;  // null = cancelled, go back to checkpoint

/** Apply adjustments to state. */
export function applyPlanAdjustment(
  state: OrchestratorState,
  adjustment: PlanAdjustment,
): OrchestratorState;
```

**UX flow** (using `ui.editor` or `ui.select`):
1. Show remaining tasks as a numbered list.
2. User interaction: `ui.editor` pre-filled with remaining tasks in YAML-like format. User deletes lines to drop, reorders lines, prefixes with `skip:` to skip.
3. Parse the edited list back into a `PlanAdjustment`.
4. Show confirmation: "Dropping tasks X, Y. Skipping Z. Reordering: [new order]. Confirm?"
5. Apply to state: dropped tasks removed from `state.tasks`, skipped tasks marked `status: "skipped"`, remaining tasks reindexed.

**Constraints enforced**:
- No new tasks (lines not matching existing task IDs are rejected).
- No editing task descriptions (description changes are ignored).
- Only pending/future tasks can be dropped/reordered. Completed tasks are fixed.

**Test**: Unit test for `applyPlanAdjustment`: drop 2 tasks → verify state.tasks shrinks. Reorder → verify new order. Skip → verify status. Attempt to drop completed task → rejected.

#### 4.4 Post-task context forwarding

Each implementer gets a lightweight summary of what prior tasks changed.

**Changes to `prompt-builder.ts`**:
```typescript
export interface PriorTaskContext {
  title: string;
  status: string;
  changedFiles: string[];
  commitSha?: string;
}

export function buildImplPrompt(
  task: TaskExecState,
  planContext: string,
  priorTasks?: PriorTaskContext[],  // replaces single previousTaskSummary
): string;
```

**What's included**: For each completed prior task: title, status, changed files list. NOT full output. Capped at last 5 tasks to avoid prompt bloat.

**Changes to `execute.ts`**:
- Before dispatching implementer, collect `priorTasks` from completed tasks in `state.tasks`.
- Pass to `buildImplPrompt`.

**Test**: Unit test for `buildImplPrompt` with prior context → verify prompt includes file lists. Test cap at 5 tasks.

### Batch 4 exit criteria
- Progress summary emitted after every task with accurate cost.
- Estimated remaining cost is reasonable (not wildly off).
- Checkpoint pauses execution on budget threshold.
- User can drop/skip/reorder tasks at checkpoint and workflow respects changes.
- Implementers receive prior task context (visible in prompt).

---

## Cross-cutting concerns

### State schema migration

Batches 2–4 add fields to `OrchestratorState` and `TaskExecState`. All new fields must be optional (`?`) for backward compatibility with in-flight workflows. When loading state, missing fields get defaults:

```typescript
// Migration in loadState or at phase entry
state.testBaseline ??= undefined;
state.gitStartingSha ??= "";
task.commitSha ??= undefined;
```

No formal migration system — just optional fields with defaults.

### Testing strategy

Each batch has:
- **Unit tests** for all pure functions (parsers, classifiers, formatters).
- **Integration tests** for state transitions (mock dispatch, real state machine).
- **At least one acceptance test** per batch that exercises the end-to-end flow for the batch's key scenario.

Acceptance tests use the existing pattern: mock `ui.*` methods, mock `dispatchAgent`, verify state transitions and UI calls.

### Config backward compatibility

New config keys have defaults that preserve current behavior:
- `testCommand`: `""` (no cross-task validation unless configured)
- `validationCadence`: `"every"`
- `gitIgnorePatterns`: `[]`

Existing `.superteam.json` files work unchanged.

---

## Summary of new files

| File | Batch | Purpose |
|------|-------|---------|
| `src/workflow/test-baseline.ts` | 2 | Test baseline capture & failure classification |
| `src/workflow/failure-taxonomy.ts` | 2 | Failure types, default actions, resolution |
| `src/workflow/git-preflight.ts` | 3 | Pre-workflow git safety checks |
| `src/workflow/checkpoint.ts` | 4 | Checkpoint triggers, presentation, plan revision |

## Summary of modified files

| File | Batches | Changes |
|------|---------|---------|
| `src/config.ts` | 1 | New config keys |
| `src/dispatch.ts` | 1 | `hasWriteToolCalls()` |
| `src/workflow/orchestrator-state.ts` | 2,3,4 | New state fields |
| `src/workflow/orchestrator.ts` | 3 | Git preflight at workflow start |
| `src/workflow/phases/execute.ts` | 1,2,3,4 | Validation, commits, checkpoints, context |
| `src/workflow/phases/plan-review.ts` | 1 | Write-guard, targeted revision, convergence |
| `src/workflow/prompt-builder.ts` | 1,4 | Targeted revision prompt, prior context |
| `src/workflow/git-utils.ts` | 3 | `commitTaskChanges()` |
| `src/workflow/progress.ts` | 4 | `computeProgressSummary()` |
| `src/workflow/ui.ts` | 4 | Summary formatting |
| `agents/*.md` | 1 | Role separation prompts |

---

## What v0.3 does NOT include

Per roadmap, explicitly out of scope:
- Brainstorm triage / complexity assessment (v0.4)
- Workflow chunking / splitting (v0.4)
- Rich finalize report / artifact archival (v0.5)
- Commit squash (v0.5 — uses the per-task commits v0.3 creates)
- Parallel task execution (Later)
- Full `/workflow revise` with arbitrary edits (Later)
